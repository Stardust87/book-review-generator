{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP book review generator",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-bHS6nJdz50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "e82e9ab6-7e68-456a-efbd-ff84d60fe5e1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RZJEVb6dbUv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee89ce9-f281-44c0-ec3d-215e772a2eee"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXikLtVVeiuu",
        "colab_type": "text"
      },
      "source": [
        "# Load GPT-2 Medium "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJpuU_9dvna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0dc83d91-9682-40a3-8625-41bf743dde82"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', model_max_length=1024)\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model = model.to(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYjQE8lPppK5",
        "colab_type": "text"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0yxogS8d90v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelWrapper:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    def generate(self, prompt, keywords, category):\n",
        "        input = '<|startoftext|>'\n",
        "        if category:\n",
        "            assert category in ['positive', 'negative']\n",
        "            input += f'~`{category}'\n",
        "        if keywords:\n",
        "            keywords = [ k.replace(' ', '-') for k in keywords ]\n",
        "            input += f\"~^{' '.join(keywords)}\"\n",
        "        \n",
        "        input += f\"~@{prompt if prompt else ''}\"\n",
        "        input_encoded = self.tokenizer.encode(input, return_tensors='pt').to(self.device)\n",
        "\n",
        "        # TODO: make these settings adjustable\n",
        "        outputs = self.model.generate(\n",
        "            input_encoded,\n",
        "            do_sample=True, \n",
        "            max_length=600, \n",
        "            top_k=30, \n",
        "            top_p=0.96, \n",
        "            num_return_sequences=3\n",
        "        )\n",
        "\n",
        "        # TODO: select outputs with keywords (?)\n",
        "        outputs_decoded = [ self.tokenizer.decode(out, skip_special_tokens=True) for out in outputs ]\n",
        "        return outputs_decoded\n",
        "\n",
        "def lambda_lr(epoch):\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_exponential_decay():\n",
        "    pass\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld2jV9AJjk7H",
        "colab_type": "text"
      },
      "source": [
        "# Reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Qw6cZr4KA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4484abc-328e-4d44-a933-5ce193710a93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o6HT6QX4by3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a366071e-0f32-40a9-904c-a98904aac85a"
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/Data Science/Datasets'\n",
        "!ls '$DATA_PATH'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reviews_nlp_encoded_balanced.txt  reviews_nlp_encoded.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjVKNlOlg79K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "MAX_SEQ_LEN = 1000\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        super().__init__()\n",
        "\n",
        "        with open(filename) as data_file:\n",
        "          self.reviews = data_file.readlines()\n",
        "        \n",
        "        self.join_sequences()\n",
        "\n",
        "    def join_sequences(self):\n",
        "        joined = []\n",
        "        temp_reviews_tens = None\n",
        "        for review in self.reviews:\n",
        "            # fit as many review sequences into MAX_SEQ_LEN sequence as possible\n",
        "            review_tens = torch.tensor(tokenizer.encode(review, max_length=MAX_SEQ_LEN, truncation=True)).unsqueeze(0)\n",
        "\n",
        "            # the first review sequence in the sequence\n",
        "            if not torch.is_tensor(temp_reviews_tens):\n",
        "                temp_reviews_tens = review_tens\n",
        "                continue\n",
        "            else:\n",
        "                # the next review does not fit in so we process the sequence and leave the last review \n",
        "                # as the start for next sequence \n",
        "                if temp_reviews_tens.size()[1] + review_tens.size()[1] < MAX_SEQ_LEN:\n",
        "                    # add the review to sequence, continue and try to add more\n",
        "                    temp_reviews_tens = torch.cat([temp_reviews_tens, review_tens[:, 1:]], dim=1)\n",
        "                    continue\n",
        "                else:\n",
        "                    work_reviews_tens, temp_reviews_tens = temp_reviews_tens, review_tens\n",
        "            joined.append(work_reviews_tens)\n",
        "          \n",
        "        self.encoded_joined_seq = joined\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_joined_seq)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_joined_seq[idx]\n",
        "\n",
        "review_dataset = ReviewsDataset(f'{DATA_PATH}/reviews_nlp_encoded_balanced.txt')\n",
        "review_loader = DataLoader(review_dataset, batch_size=1, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WePSCj4DTvm",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLfOsi8BDETo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "EPOCHS = 8\n",
        "LEARNING_RATE = 1e-5\n",
        "WARMUP_FRAC = 0.2\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zChsgrqpwsiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da6f25d9-8b33-4775-fbb0-c5304feaf759"
      },
      "source": [
        "len(review_loader)*EPOCHS//BATCH_SIZE"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpL9nymxDyAO",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3-izXatDz1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "16e0b704-ecc4-4622-886a-32b6ba65ff93"
      },
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "steps = len(review_loader)*EPOCHS//BATCH_SIZE\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(WARMUP_FRAC*steps), num_training_steps=steps)\n",
        "\n",
        "\n",
        "loss_history = []\n",
        "batch_count = 0\n",
        "reviews_count = 0\n",
        "loss_every = 100\n",
        "\n",
        "temp_reviews_tens = None\n",
        "models_dir = \"models\"\n",
        "if not os.path.exists(models_dir):\n",
        "    os.mkdir(models_dir)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"EPOCH {epoch+1}\")\n",
        "    epoch_loss_history = []\n",
        "  \n",
        "    for review_tens in review_loader:\n",
        "        review_tens = review_tens.to(device)\n",
        "                \n",
        "        # sequence ready, process it trough the model\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(review_tens, labels=review_tens)\n",
        "        loss, logits = outputs[:2]                        \n",
        "        loss.backward()\n",
        "        epoch_loss_history.append(loss.detach().item())\n",
        "                       \n",
        "        reviews_count += 1\n",
        "        if reviews_count == BATCH_SIZE:\n",
        "            reviews_count = 0\n",
        "            batch_count += 1\n",
        "            optimizer.step()\n",
        "            scheduler.step() \n",
        "\n",
        "        if batch_count == loss_every:\n",
        "            batch_count = 0\n",
        "            avg_loss = np.array(epoch_loss_history)[-loss_every*BATCH_SIZE+1:].mean()\n",
        "            print(f'Avg. loss: {avg_loss:.4f}')\n",
        "    \n",
        "    loss_history.append(torch.tensor(epoch_loss_history))\n",
        "    # store the model after each epoch to compare the performance of them\n",
        "    torch.save(model.state_dict(), os.path.join(models_dir, f\"review_model_e{epoch+1}.pt\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1\n",
            "Avg. loss: 3.6317\n",
            "Avg. loss: 3.2692\n",
            "Avg. loss: 2.9938\n",
            "Avg. loss: 2.8743\n",
            "Avg. loss: 2.8129\n",
            "EPOCH 2\n",
            "Avg. loss: 2.5630\n",
            "Avg. loss: 2.6838\n",
            "Avg. loss: 2.6536\n",
            "Avg. loss: 2.6651\n",
            "Avg. loss: 2.7031\n",
            "Avg. loss: 2.6969\n",
            "EPOCH 3\n",
            "Avg. loss: 2.6836\n",
            "Avg. loss: 2.6036\n",
            "Avg. loss: 2.6049\n",
            "Avg. loss: 2.6010\n",
            "Avg. loss: 2.6090\n",
            "Avg. loss: 2.6174\n",
            "EPOCH 4\n",
            "Avg. loss: 2.5218\n",
            "Avg. loss: 2.5201\n",
            "Avg. loss: 2.5620\n",
            "Avg. loss: 2.6118\n",
            "Avg. loss: 2.5853\n",
            "Avg. loss: 2.5530\n",
            "EPOCH 5\n",
            "Avg. loss: 2.5556\n",
            "Avg. loss: 2.5799\n",
            "Avg. loss: 2.5035\n",
            "Avg. loss: 2.5234\n",
            "Avg. loss: 2.5576\n",
            "Avg. loss: 2.5856\n",
            "EPOCH 6\n",
            "Avg. loss: 2.5712\n",
            "Avg. loss: 2.5169\n",
            "Avg. loss: 2.5371\n",
            "Avg. loss: 2.5633\n",
            "Avg. loss: 2.5230\n",
            "Avg. loss: 2.5354\n",
            "EPOCH 7\n",
            "Avg. loss: 2.5047\n",
            "Avg. loss: 2.4946\n",
            "Avg. loss: 2.5477\n",
            "Avg. loss: 2.5100\n",
            "Avg. loss: 2.5019\n",
            "Avg. loss: 2.5609\n",
            "EPOCH 8\n",
            "Avg. loss: 2.4949\n",
            "Avg. loss: 2.5348\n",
            "Avg. loss: 2.5014\n",
            "Avg. loss: 2.5037\n",
            "Avg. loss: 2.5319\n",
            "Avg. loss: 2.5259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N81rgHj-nkIf",
        "colab_type": "text"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuNWJIUZYSWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43b7fafb-e2c9-44a1-bf4b-4483c64b9dc7"
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('models/review_model_e8.pt'))\n",
        "model.eval()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2y9rfNgn530",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrapped_model = ModelWrapper(model, tokenizer)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIiwDEkvoCLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3bca6648-1e64-4e62-fdb2-9e197eae5e93"
      },
      "source": [
        "wrapped_model.generate('', ['dog'], 'bad')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|startoftext|>~`bad~^dog~@This book had such a nice ring to it that if a dog bites you, it will eat you. It was so easy to read, so you could feel the force of the dog's bite. I loved seeing the dog on the porch in the backyard to see what was going on with the dog's coat, and the dog would come up and walk away with no coat, no leash. There were very few people around the house and I didn't notice any unusual behaviors, which made it even more interesting to me. The book is not for the timid dog, but the one with a weak heart and a lack of a strong jaw. It is a great story, but not one you would normally read for someone who is very young.\",\n",
              " \"<|startoftext|>~`bad~^dog~@This book is terrible! I read it in the winter when I was in Italy and I didn't care about being a dog. It really doesn't do it for me. The way they are treated in this book is disgusting. I didn't care that they had a leash around the dog. It's an awful dog that I was terrified of and was hoping she would be taken away so she could get back to her family where she lived and keep her dog. It was awful! I will not be going back for another book in the series. I have so many books I want to finish. My book club is going to need some people to meet and talk about this. It is hard to follow when a child has just come back from a difficult time and you are trying to keep them away from the dog and then you can see a few pictures of the kids with this dog. I hope to read more of the series because it is a great way to learn more about dogs.\",\n",
              " '<|startoftext|>~`bad~^dog~@Did not like the premise of this book, not in the sense of \"it\\'s a dog book\". But I guess that this is a very well written book that doesn\\'t need any more convincing.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIH1j6JioHAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}